import streamlit as st
import google.generativeai as genai
from PIL import Image
from gtts import gTTS
import os
from streamlit_mic_recorder import mic_recorder

# 1. Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø©
st.set_page_config(page_title="X Assistant V2", page_icon="ğŸ¤–")
st.title("ğŸ¤– X Assistant V2")
st.markdown("ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø¨Ø±Ù…Ø¬: **Ø£Ø­Ù…Ø¯ Ø§Ù„Ø­Ø±ÙŠÙ**")

# 2. ØªÙØ¹ÙŠÙ„ Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø­Ø± Ø§Ù„Ù„ÙŠ Ø¨Ø¹ØªÙ‡
genai.configure(api_key="AIzaSyDKPuAj8fjSvp5ykmHeyKGRpUSO-V6fTVE")

# 3. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©
st.sidebar.title("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Harreef ğŸ˜")
uploaded_file = st.sidebar.file_uploader("ğŸ“¸ Ø§Ø¨Ø¹Øª ØµÙˆØ±Ø© Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯:", type=["jpg", "png", "jpeg"])

# ÙˆØ¸ÙŠÙØ© Ø§Ù„ØµÙˆØª
def speak(text):
    try:
        tts = gTTS(text=text, lang='ar')
        tts.save("voice.mp3")
        st.audio("voice.mp3", format='audio/mp3', autoplay=True)
    except:
        pass

if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø§Øª
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# 4. Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµÙˆØª ÙˆØ§Ù„Ù†Øµ
st.write("ğŸ¤ Ø³Ø¬Ù„ ØµÙˆØªÙƒ ÙŠØ§ Ø­Ø±ÙŠÙ:")
audio_data = mic_recorder(start_prompt="Ø¯ÙˆØ³ ÙˆØ§Ø¨Ø¯Ø£ ÙƒÙ„Ø§Ù…", stop_prompt="Ø§Ø±Ø³Ù„ Ø§Ù„Ø·Ù„Ø¨", key='recorder')
prompt = st.chat_input("Ø§Ø³Ø£Ù„ X Assistant V2...")

if prompt or audio_data:
    user_input = prompt if prompt else "Ø­Ù„Ù„ Ø§Ù„Ù„ÙŠ Ø³Ù…Ø¹ØªÙ‡ Ø£Ùˆ Ø§Ù„Ù„ÙŠ Ø´Ø§ÙŠÙÙ‡ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©"
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    with st.chat_message("assistant"):
        model = genai.GenerativeModel('gemini-1.5-flash')
        # ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ© (Ø²ÙŠ Ù…Ø§ Ø·Ù„Ø¨Øª Ø¨Ø§Ù„Ø¸Ø¨Ø·)
        sys_msg = "Ø£Ù†Øª X Assistant V2ØŒ Ù…Ø¨Ø±Ù…Ø¬Ùƒ Ø£Ø­Ù…Ø¯ Ø§Ù„Ø­Ø±ÙŠÙ. Ø±Ø¯ Ø¨Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø§Ù„Ù…ØµØ±ÙŠØ© Ø¨Ø·Ù„Ø§Ù‚Ø© ÙˆÙ†Ø§Ø¯ÙŠÙ‡ ÙŠØ§ Ø­Ø±ÙŠÙ Ø£Ùˆ ÙŠØ§ Ø£Ø­Ù…Ø¯."
        
        if uploaded_file:
            img = Image.open(uploaded_file)
            response = model.generate_content([f"{sys_msg} {user_input}", img])
        else:
            response = model.generate_content(f"{sys_msg} {user_input}")
            
        res_text = response.text
        st.markdown(res_text)
        speak(res_text) # Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ù‡ÙŠÙ†Ø·Ù‚ Ø§Ù„Ø±Ø¯
        st.session_state.messages.append({"role": "assistant", "content": res_text})
      
